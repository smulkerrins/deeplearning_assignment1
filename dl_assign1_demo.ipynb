{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7898e471-c7b6-4576-8fd4-b8d75d695153",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Import Libraries and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d53ad2f-7721-4deb-ad23-7b0d20594e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and set default options\n",
    "import datetime\n",
    "import calendar\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from array import array\n",
    "import pickle\n",
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import NMF, PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import  datasets, layers, models\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout, SimpleRNN, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "cifar100_labels = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5c6de9b-500b-47d5-9306-3f135358db13",
   "metadata": {},
   "source": [
    "# Part 2: Transfer Learning and Image Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14185cc3-3e24-4c6e-9960-103de2a0e11d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c1d3f-36a1-4714-a2d9-90f5ea9e55e8",
   "metadata": {},
   "source": [
    "### Load saved models and data\n",
    "\n",
    "**Note:**\n",
    "Some known bugs in tensorflow on M1 based Macs have led to issues with serialising and deserialising models, blocking the use of .keras or .pkl formats and forcing the use of the legacy .h5. This also appears to be forcing the optimizer to reinitialise which may lead to different results here than in the training notebooks.\n",
    "\n",
    "See:\\\n",
    "https://github.com/tensorflow/tensorflow/issues/61915 \\\n",
    "https://github.com/keras-team/tf-keras/issues/46 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c110c1f-5d05-47a1-8679-a2ac9c43ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnBlockTwoSet(block2_classes):\n",
    "    (train_images, train_labels), (test_images, test_labels) = datasets.cifar100.load_data(label_mode='fine')\n",
    "\n",
    "    class_names = test_labels.reshape(-1) \n",
    "    # Normalise pixel values 0-1\n",
    "    train_images_normalised, test_images_normalised = train_images / 255.0, test_images / 255.0\n",
    "    \n",
    "    # block2_classes = classes[50:]\n",
    "\n",
    "    train_labels = train_labels.reshape(-1)\n",
    "    test_labels = test_labels.reshape(-1)\n",
    "\n",
    "    train_mask2 = np.isin(train_labels, block2_classes)\n",
    "    test_mask2 = np.isin(test_labels, block2_classes)\n",
    "\n",
    "    train_images_2 = np.take(train_images_normalised, np.where(train_mask2)[0], axis=0)\n",
    "    train_labels_2 = np.take(train_labels, np.where(train_mask2)[0])\n",
    "    test_images_2 = np.take(test_images_normalised, np.where(test_mask2)[0], axis=0)\n",
    "    test_labels_2 = np.take(test_labels, np.where(test_mask2)[0])\n",
    "\n",
    "    return train_images_2, train_labels_2, test_images_2, test_labels_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adddc2d-f4e9-468c-a78e-e720a7712bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    print(f\"Part 2: Loading saved models and data\")\n",
    "    part2imgclass_bestmodel_url = \"https://github.com/smulkerrins/dlassignment/raw/refs/heads/main/part2imgclass_bestmodel.h5\"\n",
    "    filename = 'part2imgclass_bestmodel.h5'\n",
    "    r = requests.get(part2imgclass_bestmodel_url)\n",
    "    f = open(filename,'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "    \n",
    "    part2imgclass_autoencoder_url = \"https://github.com/smulkerrins/dlassignment/raw/refs/heads/main/part2imgclass_autoencoder.h5\"\n",
    "    filename = 'part2imgclass_autoencoder.h5'\n",
    "    r = requests.get(part2imgclass_autoencoder_url)\n",
    "    f = open(filename,'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "    \n",
    "    part2_block2_classes_url = \"https://github.com/smulkerrins/dlassignment/raw/refs/heads/main/part2_block2_classes.pkl\"\n",
    "    filename = 'part2_block2_classes.pkl'\n",
    "    r = requests.get(part2_block2_classes_url)\n",
    "    f = open(filename,'wb')\n",
    "    f.write(r.content)\n",
    "    f.close()\n",
    "    \n",
    "    print(f\"Part 2: Files downloaded\")\n",
    "\n",
    "    part2imgclass_bestmodel = tf.keras.models.load_model('part2imgclass_bestmodel.h5')\n",
    "    part2imgclass_autoencoder = tf.keras.models.load_model('part2imgclass_autoencoder.h5')\n",
    "    \n",
    "    with open(\"part2_block2_classes.pkl\", 'rb') as part2_block2_classes_picklefile:\n",
    "        block_classes = pickle.load(part2_block2_classes_picklefile)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"Part 2: Saved models and data loaded\")\n",
    "\n",
    "    train_images, train_labels, test_images, test_labels = returnBlockTwoSet(block_classes)\n",
    "    print(f\"Part 2: CIFAR-100 set loaded\")\n",
    "\n",
    "    return part2imgclass_bestmodel, part2imgclass_autoencoder, block_classes, train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaae96e-f896-4270-8ab5-c988efcfb5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa07ed-4225-4d1a-a60f-171924b6b876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa28f361-90d5-4abc-91c1-ea04233a023b",
   "metadata": {},
   "source": [
    "### Scoring and Plotting Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab931d3-ea67-4ef5-9f20-e2eeff96d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificationReportAndScore(model, history, test_images, test_labels, block_classes):\n",
    "    subset_class_names = np.unique([cifar100_labels[i] for i in block_classes])\n",
    "\n",
    "    # Generate predictions (using subset 1 for example)\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    true_labels_text = np.array([cifar100_labels[label] for label in test_labels])\n",
    "    predicted_labels_text = np.array([cifar100_labels[label] for label in predicted_labels])\n",
    "\n",
    "    # print(classification_report(test_labels, np.argmax(predictions, axis=1)))\n",
    "\n",
    "    report = classification_report(true_labels_text, predicted_labels_text, labels=subset_class_names, output_dict=True)\n",
    "\n",
    "    # Convert report to DataFrame\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Sort by F1-score\n",
    "    df = df.sort_values(by='f1-score', ascending=False)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "    overall_accuracy = report['accuracy'] \n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f2e33-e964-45ee-93ff-4ef598b98722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(model, history, test_images, test_labels, block_classes):\n",
    "    subset_class_names = np.unique([cifar100_labels[i] for i in block_classes])\n",
    "\n",
    "    # Generate predictions (using subset 1 for example)\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    true_labels_text = np.array([cifar100_labels[label] for label in test_labels])\n",
    "    predicted_labels_text = np.array([cifar100_labels[label] for label in predicted_labels])\n",
    "    \n",
    "    # Confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_labels_text, predicted_labels_text, labels=subset_class_names) \n",
    "    \n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Add labels to the plot\n",
    "    tick_marks = np.arange(len(subset_class_names))\n",
    "    plt.xticks(tick_marks, subset_class_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, subset_class_names)\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f20b5e-1cf0-4411-9f64-15c445218e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTrainingAndValidationLoss(train_loss, val_loss ):\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(val_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Loss')\n",
    "    # modelConfig[\"plots\"].append(plt)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plotTrainingAndValidationAccuracy(train_acc, val_acc ):\n",
    "    plt.plot(train_acc, label='Training Accuracy')\n",
    "    plt.plot(val_acc, label='Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "    # modelConfig[\"plots\"].append(plt)\n",
    "    plt.show()\n",
    "    \n",
    "def plotModel(history):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    train_acc = history.history['accuracy'] \n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    plotTrainingAndValidationLoss(train_loss, val_loss)\n",
    "    plotTrainingAndValidationAccuracy(train_acc, val_acc)\n",
    "\n",
    "def plotAutoencoder(history):\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plotTrainingAndValidationLoss(train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4b61ab-ef62-4aca-9bab-a7bb44d04f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAutoencoder(autoencoder, test_images):\n",
    "    mse = autoencoder.evaluate(test_images, test_images)  # Calculate MSE on the test set\n",
    "    print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af9b31-a8b1-4321-b24d-997ebdd5c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualTestAutoencoder(autoencoder, test_images):\n",
    "    reconstructed_images = autoencoder.predict(test_images)\n",
    "\n",
    "    for i in range(5):\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(test_images[i])\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(reconstructed_images[i])\n",
    "        plt.title(\"Reconstructed\")\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60c4670-82e9-4400-8cfb-0c96865bf48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateAndAnalyse(model, history, test_images, test_labels, block_classes):\n",
    "    subset_class_names = np.unique([cifar100_labels[i] for i in block_classes])\n",
    "\n",
    "    # Generate predictions (using subset 1 for example)\n",
    "    predictions = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    true_labels_text = np.array([cifar100_labels[label] for label in test_labels])\n",
    "    predicted_labels_text = np.array([cifar100_labels[label] for label in predicted_labels])\n",
    "    \n",
    "    # Confusion matrix\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(true_labels_text, predicted_labels_text, labels=subset_class_names) \n",
    "    \n",
    "    \n",
    "    # Plotting the confusion matrix\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Add labels to the plot\n",
    "    tick_marks = np.arange(len(subset_class_names))\n",
    "    plt.xticks(tick_marks, subset_class_names, rotation=45, ha='right')\n",
    "    plt.yticks(tick_marks, subset_class_names)\n",
    "    \n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # from sklearn.metrics import classification_report\n",
    "    print(classification_report(test_labels, np.argmax(predictions, axis=1)))\n",
    "\n",
    "    report = classification_report(true_labels_text, predicted_labels_text, labels=subset_class_names, output_dict=True)\n",
    "\n",
    "    # Convert report to DataFrame\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    \n",
    "    # Sort by F1-score\n",
    "    df = df.sort_values(by='f1-score', ascending=False)\n",
    "    \n",
    "    # Print the DataFrame\n",
    "    print(df.to_markdown(numalign=\"left\", stralign=\"left\"))\n",
    "\n",
    "\n",
    "    overall_accuracy = report['accuracy'] \n",
    "    print(f\"Overall accuracy: {overall_accuracy:.4f}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc501dd6-5697-45df-ba40-caae195ed497",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Image Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943075d5-9e13-466f-bd42-0eabc32cf064",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, autoencoder, block_classes, train_images, train_labels, test_images, test_labels = loadData()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa90d1-0c74-4b04-87bf-7a59d43cb651",
   "metadata": {},
   "source": [
    "### Training\n",
    "N/A history was impossible to serialise/deserialise due to above bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e45baa3-a5ad-4417-a341-ac7e35fa348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotModel(model.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982c4507-9664-4b04-b93f-9a79cdf23bd5",
   "metadata": {},
   "source": [
    "### Classification and Scoring\n",
    "N/A classification report and accuracy score was impossible to serialise/deserialise due to above bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc605cbb-a746-45ba-9b13-8d1a62e0ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classificationReportAndScore(model, model.history, test_images, test_labels, block_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f40c659-8cf3-4457-aa69-22e825587ede",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "N/A confusion matrix was impossible to serialise/deserialise due to above bug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d8fa8-ab26-4b57-91e1-9b6ad367a20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusionMatrix(model, model.history, test_images, test_labels, block_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdbd494-4721-42d7-a60b-bdb987482133",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abecaf3-f652-4d60-a064-1f47cf98c8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4dca79-8c48-4cd8-a959-c3abf41daa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualTestAutoencoder(autoencoder, test_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
